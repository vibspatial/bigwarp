{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigWarp .zarr to OME-TIFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a conda environment\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "conda activate zarr-ometiff\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import downscale_local_mean\n",
    "from typing import Dict, List, Optional, Tuple, Iterator\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import math\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _zarr_image_get_pixelsize_um(root, group_name) -> Tuple[float, float]:\n",
    "    # As an example a transform attribute for an image channel in a Bigwarp zarr:\n",
    "    # {'axes': ['y', 'x'], 'scale': [0.0002495152876362007, 0.0002495152876362007, 0.001], 'translate': [0.0, 0.0, 0.0], 'units': ['mm', 'mm']}\n",
    "    # It is inconsistent because sometimes it specifies three dimensions, and sometimes two.\n",
    "    transform = root[group_name].attrs['transform']\n",
    "    print(f'Image transform {transform}')\n",
    "\n",
    "    assert transform['axes'] == ['y', 'x']\n",
    "    assert transform['translate'] == [0.0, 0.0, 0.0]\n",
    "    assert transform['units'] == ['mm', 'mm']\n",
    "\n",
    "    scale = transform['scale']\n",
    "    assert len(scale) == 3  # the 3rd dimensions is probably a default z-plane distance of 1 micron\n",
    "\n",
    "    pixel_size_y_um = scale[0] * 1000.0 \n",
    "    pixel_size_x_um = scale[1] * 1000.0\n",
    "\n",
    "    return (pixel_size_y_um, pixel_size_x_um)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function\n",
    "def write_pyramidal_ome_tiff(img_stack: da.Array,                # dask array image stack of shape (channels, y, x)\n",
    "                             pyramid_filename: str,\n",
    "                             channel_names: Optional[List[str]],\n",
    "                             pixel_size_um: Optional[Tuple[float, float]],        # pixel size in microns, or None\n",
    "                             compression: Optional[str],         # 'zlib' or None\n",
    "                             tile_size: int,                     # tile size (in pixels) in output OME TIFF file\n",
    "                             max_levels: int,\n",
    "                             downsample_method: str) -> None:    # downsample method = 'box' (better quality, slower) or 'nearest neighbor' (faster, poorer quality)\n",
    "\n",
    "    num_pyramid_levels: int = max_levels  # CHECKME: do we need to clip this value in case we would end up with <= 1 pixel images in the pyramid?\n",
    "\n",
    "    ome_metadata = _make_ome_metadata(img_stack, channel_names, pixel_size_um)\n",
    "\n",
    "    tile_sizes = (tile_size, tile_size)\n",
    "\n",
    "    options = dict(tile=tile_sizes,\n",
    "                   photometric='minisblack',\n",
    "                   compression=compression,\n",
    "                   metadata=ome_metadata,\n",
    "                   software=_creator())\n",
    "    \n",
    "    num_channels, image_height, image_width = img_stack.shape\n",
    "\n",
    "    # Create output folder if it does not exist yet.\n",
    "    Path(pyramid_filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f'Writing pyramidal OME TIFF file {pyramid_filename} (compression: {options[\"compression\"]})')\n",
    "    with tifffile.TiffWriter(pyramid_filename, ome=True, bigtiff=True) as tif:\n",
    "        \n",
    "        # Write full resolution image\n",
    "        print(f'Writing level 0: {image_width} x {image_height} px')\n",
    "        downsample_factor = 1\n",
    "        tif.write(data=_tiles_generator(img_stack, tile_sizes, downsample_factor, downsample_method),\n",
    "                  shape=(num_channels, image_height, image_width, 1),\n",
    "                  dtype=img_stack.dtype,\n",
    "                  subifds=num_pyramid_levels-1,\n",
    "                  **options)\n",
    "\n",
    "        # Save downsampled pyramid images to the subifds\n",
    "        for level in range(1, num_pyramid_levels):\n",
    "            downsampled_data_shape = math.ceil(image_height / (2**level)), math.ceil(image_width / (2**level))\n",
    "            print(f'Writing level {level}: {downsampled_data_shape[1]} x {downsampled_data_shape[0]} px')\n",
    "            downsample_factor = 2**level\n",
    "            tif.write(data=_tiles_generator(img_stack, tile_sizes, downsample_factor, downsample_method), \n",
    "                      shape=(num_channels, downsampled_data_shape[0], downsampled_data_shape[1], 1),\n",
    "                      dtype=img_stack.dtype,\n",
    "                      subfiletype=1,\n",
    "                      **options)\n",
    "\n",
    "\n",
    "def _tiles_generator(img_stack: da.Array,\n",
    "                     tile_sizes: Tuple[int, int],\n",
    "                     downsample_factor: int,\n",
    "                     downsample_method: str) -> Iterator[np.ndarray]:\n",
    "    # See also https://forum.image.sc/t/tifffile-ome-tiff-generation-is-taking-too-much-ram/41865/16\n",
    "    # and https://github.com/labsyspharm/ashlar/blob/5bf5b8710f456e68e33ff232708cda0b1c904a33/ashlar/reg.py\n",
    "    tile_height, tile_width = tile_sizes\n",
    "    num_channels = img_stack.shape[0]\n",
    "    for c in range(num_channels):\n",
    "        print(f'  channel {c+1}/{num_channels}')\n",
    "\n",
    "        # Get a full numpy array image from the dask array.\n",
    "        # This loses dask chunk advantages (limited peak memory consumption), but avoids tiling artefacts in our naive downsampling implementation.\n",
    "        # It also makes our retiling (from dask chunk size to OME TIFF tile size) trivial.\n",
    "        # IMPROVEME: for downsampling of the original dask arrays we may get some inspiration here:\n",
    "        # https://github.com/spatial-image/multiscale-spatial-image/blob/0c6f65cdc69cb069e81cdc07e7f3f5441f0cc4e5/multiscale_spatial_image/to_multiscale/_dask_image.py#L100\n",
    "        # However, we may still need to retile afterwards.\n",
    "        image = img_stack[c].compute()  \n",
    "\n",
    "        # Downsample\n",
    "        image = _downsample_image(image, downsample_factor, downsample_method)\n",
    "\n",
    "        # Generate tiles\n",
    "        image_height, image_width = image.shape\n",
    "        for y in range(0, image_height, tile_height):\n",
    "            for x in range(0, image_width, tile_width):\n",
    "                yield image[y:y+tile_height, x:x+tile_width].copy()\n",
    "\n",
    "\n",
    "def _downsample_image(img: np.ndarray,\n",
    "                      downsample_factor: int,\n",
    "                      downsample_method: str) -> np.ndarray:\n",
    "\n",
    "    if downsample_factor != 1:\n",
    "        if downsample_method == 'box':\n",
    "            # Box filter. This yields dramatically better quality than nearest neighbor but is slower.\n",
    "            img = downscale_local_mean(img, (downsample_factor, downsample_factor)).astype(img.dtype)\n",
    "        else:\n",
    "            # Nearest neighbor downsampling. Fast but poor quality.\n",
    "            img = img[::downsample_factor, ::downsample_factor]\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def _make_ome_metadata(img_stack: da.Array,\n",
    "                       channel_names: Optional[List[str]],\n",
    "                       pixel_size_um: Optional[Tuple[float, float]]):\n",
    "\n",
    "    # Collect OME metadata\n",
    "    ome_metadata = {}\n",
    "    ome_metadata['Creator'] = _creator()\n",
    "    if pixel_size_um:\n",
    "        pixel_size_y_um, pixel_size_x_um = pixel_size_um\n",
    "        print(f'Pixel size: {pixel_size_um} micrometer')\n",
    "        ome_metadata['PhysicalSizeX'] = str(pixel_size_x_um)\n",
    "        ome_metadata['PhysicalSizeXUnit'] = 'µm'\n",
    "        ome_metadata['PhysicalSizeY'] = str(pixel_size_y_um)\n",
    "        ome_metadata['PhysicalSizeYUnit'] = 'µm'\n",
    "\n",
    "    if channel_names:\n",
    "        print(f'Channel names: {channel_names}')\n",
    "        assert len(channel_names) == img_stack.shape[0]\n",
    "        ome_metadata['Channel'] = {'Name': channel_names}\n",
    "\n",
    "    return ome_metadata    \n",
    "\n",
    "\n",
    "def _creator() -> str:\n",
    "    return f'zarr-ometiff'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_name_to_channel_name(group_name: str, renaming_dict: Optional[Dict[str, str]]=None) -> str:\n",
    "   # A group name look like this: '/warped/001_AntigenCycle_Donkey_anti-goat-FITC_V50_FITC_16bit_M-20x-S_Fluor_full_sensor_B-1_R-6_W-0_G-1_F-1_E-1200.0.tif-Donkey'\n",
    "    # we extract the channel name as the part after the second'/'.\n",
    "    channel_name = group_name.split('/')[2]\n",
    "\n",
    "    # Optionally rename channel\n",
    "    if renaming_dict:\n",
    "        channel_name = renaming_dict[channel_name]\n",
    "\n",
    "    return channel_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open BigWarp .zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open zarr\n",
    "zarr_path = r'D:\\Frank\\BigWarp-Troubleshooting-MarineLab\\bigwarp.zarr'\n",
    "assert Path.exists(Path(zarr_path))\n",
    "\n",
    "root = zarr.open(zarr_path, 'r')\n",
    "# NOTE: Set path to your BigWarp Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check contents of Zarr\n",
    "root.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the first group in the zarr (in the case of bigwarp zarr there is only one)\n",
    "group_key = list(root)[0]\n",
    "group = root[group_key]\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_group_names = [item[1].name for item in group.items()]\n",
    "channel_group_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual exploration of the zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first channel as an example\n",
    "img = root[channel_group_names[0]]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The physical pixel size can be recovered from the zarr attributes dictionary associated with the zarr group holding the (single channel) image.\n",
    "img.attrs['transform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot image\n",
    "plt.imshow(img[::4,::4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyramidal OME-TIFF Writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save zarr as single channel OME-TIFFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "tile_size: int = 1024\n",
    "max_levels: int = 6         # number of image pyramid levels\n",
    "downsample_method = 'box'\n",
    "compression = 'zlib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary for mapping BigWarp channel names back to the original filenames.\n",
    "orig_filenames = {\n",
    "    'cycle2-s0-DAPI' : 'some_other_filename_DAPI',\n",
    "    'cycle2-s0-Opal_520' : 'some_other_filename_Opal_520',\n",
    "    'cycle2-s0-Opal_570' : 'some_other_filename_Opal_570',\n",
    "    'cycle2-s0-Opal_690' : 'some_other_filename_Opal_690',\n",
    "    'cycle2-s0-Opal_780' : 'some_other_filename_Opal_780',\n",
    "    'cycle2-s0-Sample_AF' : 'some_other_filename_Sample_AF'\n",
    "}\n",
    "# NOTE: Change these names to the BigWarp channel names and the desired output names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to output folder\n",
    "output_folder = r'D:\\Frank\\BigWarp-Troubleshooting-MarineLab\\registered'\n",
    "# NOTE: Specify the folder where you want to save the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert zarr to single-channels OME-TIFFs\n",
    "for channel, channel_group_name in enumerate(channel_group_names):\n",
    "    channel_name = group_name_to_channel_name(channel_group_name, orig_filenames)\n",
    "\n",
    "    print(f'Channel {channel}: {channel_group_name} -> {channel_name}')\n",
    "\n",
    "    pyramid_filename = os.path.join(output_folder, f'{channel_name}.tif')\n",
    "\n",
    "    img_channel = da.expand_dims(da.array(root[channel_group_name]), axis=0)\n",
    "\n",
    "    pixel_size_um: Tuple[float, float] = _zarr_image_get_pixelsize_um(root, f'{channel_group_name}')\n",
    "\n",
    "    write_pyramidal_ome_tiff(img_channel,\n",
    "                             pyramid_filename,\n",
    "                             [channel_name],\n",
    "                             pixel_size_um,\n",
    "                             compression,\n",
    "                             tile_size,\n",
    "                             max_levels,\n",
    "                             downsample_method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
